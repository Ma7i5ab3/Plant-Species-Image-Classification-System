{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LINK GOOGLE DRIVE**"
      ],
      "metadata": {
        "id": "NwUyftHp-BUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvRU5vPv9cuI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /gdrive/My Drive/Colab Notebook"
      ],
      "metadata": {
        "id": "rdgqmBGF-ReN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT LIBRARIES AND INITIALIZATION RANDOM SEED**"
      ],
      "metadata": {
        "id": "5U3dS04A-i7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "eWwjjN-t-Tv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "vnGAFQGH-_wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConvNextLarge model uses tensorflow version 2.10**"
      ],
      "metadata": {
        "id": "8jNuPIuR-qOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.10"
      ],
      "metadata": {
        "id": "6FDFLAf0-cza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING DATASET AND SPLITTING DATA**"
      ],
      "metadata": {
        "id": "NfMF6qCc_ii5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We use the libraries splitfolders to generate new folders with a random splitting of the data in train and validation part\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "!unzip training_dataset_homework1.zip\n",
        "dataset_dir = 'training_data_final'\n",
        "labels = ['Species1',       \n",
        "          'Species2',          \n",
        "          'Species3',    \n",
        "          'Species4',             \n",
        "          'Species5',          \n",
        "          'Species6',         \n",
        "          'Species7',   \n",
        "          'Species8']\n",
        "\n",
        "splitfolders.ratio('training_data_final', output=\"train_data_final_80_20\", seed=42, ratio=(0.80, 0.20, 0.0), group_prefix=None, move=False) "
      ],
      "metadata": {
        "id": "Fdj_Pf7O-3au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINITION OF CLASS AND FUNCTIONS FOR MIXUP AND CUTOUT IMPLEMENTATION**"
      ],
      "metadata": {
        "id": "2iOrg4PsAQkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *Class defintion for MixUp Implementation*"
      ],
      "metadata": {
        "id": "vADiOlkHAdzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MixupImageDataGenerator():\n",
        "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.1):\n",
        "        \"\"\"Constructor for mixup image data generator.\n",
        "        Arguments:\n",
        "            generator {object} -- An instance of Keras ImageDataGenerator.\n",
        "            directory {str} -- Image directory.\n",
        "            batch_size {int} -- Batch size.\n",
        "            img_height {int} -- Image height in pixels.\n",
        "            img_width {int} -- Image width in pixels.\n",
        "        Keyword Arguments:\n",
        "            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n",
        "            subset {str} -- 'training' or 'validation' if validation_split is specified in\n",
        "            `generator` (ImageDataGenerator).(default: {None})\n",
        "        \"\"\"\n",
        "\n",
        "        self.batch_index = 0\n",
        "        self.batch_size = batch_size\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # First iterator yielding tuples of (x, y)\n",
        "        self.generator1 = generator.flow_from_directory(directory,\n",
        "                                                        target_size=(\n",
        "                                                            img_height, img_width),\n",
        "                                                        class_mode=\"categorical\",\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True)\n",
        "\n",
        "        # Second iterator yielding tuples of (x, y)\n",
        "        self.generator2 = generator.flow_from_directory(directory,\n",
        "                                                        target_size=(\n",
        "                                                            img_height, img_width),\n",
        "                                                        class_mode=\"categorical\",\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=True)\n",
        "\n",
        "        # Number of images across all classes in image directory.\n",
        "        self.n = self.generator1.samples\n",
        "\n",
        "    def reset_index(self):\n",
        "        \"\"\"Reset the generator indexes array.\n",
        "        \"\"\"\n",
        "\n",
        "        self.generator1._set_index_array()\n",
        "        self.generator2._set_index_array()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.reset_index()\n",
        "\n",
        "    def reset(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        # round up\n",
        "        return (self.n + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "    def get_steps_per_epoch(self):\n",
        "        \"\"\"Get number of steps per epoch based on batch size and\n",
        "        number of images.\n",
        "        Returns:\n",
        "            int -- steps per epoch.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.n // self.batch_size\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Get next batch input/output pair.\n",
        "        Returns:\n",
        "            tuple -- batch of input/output pair, (inputs, outputs).\n",
        "        \"\"\"\n",
        "\n",
        "        if self.batch_index == 0:\n",
        "            self.reset_index()\n",
        "\n",
        "        current_index = (self.batch_index * self.batch_size) % self.n\n",
        "        if self.n > current_index + self.batch_size:\n",
        "            self.batch_index += 1\n",
        "        else:\n",
        "            self.batch_index = 0\n",
        "\n",
        "        # Get a pair of inputs and outputs from two iterators.\n",
        "        X1, y1 = self.generator1.next()\n",
        "        X2, y2 = self.generator2.next()\n",
        "\n",
        "        # random sample the lambda value from beta distribution.\n",
        "        l = np.random.beta(self.alpha, self.alpha, X1.shape[0])\n",
        "\n",
        "        X_l = l.reshape(X1.shape[0], 1, 1, 1)\n",
        "        y_l = l.reshape(X1.shape[0], 1)\n",
        "\n",
        "        # Perform the mixup.\n",
        "        X = X1 * X_l + X2 * (1 - X_l)\n",
        "        y = y1 * y_l + y2 * (1 - y_l)\n",
        "        return X, y\n",
        "\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            yield next(self)"
      ],
      "metadata": {
        "id": "PNOXTpQoAFHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *Function definition for CutOut implementation*"
      ],
      "metadata": {
        "id": "9O3AX6opBsW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_out(p=0.8, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "metadata": {
        "id": "gWDAaVGoBhvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRE-PROCESSING OF THE DATA AND AUGMENTATION**\n",
        "\n",
        "\n",
        "> *Initialization of different data generators*\n",
        "\n"
      ],
      "metadata": {
        "id": "5b29oth4CfDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess_input is usefull to preprocess the data so we'll have pixel in range of values [0,1]\n",
        "from tensorflow.keras.applications.convnext import preprocess_input\n",
        "\n",
        "#This function is usefull to do cutout augmentation\n",
        "def custom_function(input_image):\n",
        "    input_image = preprocess_input(input_image)\n",
        "    return cut_out(v_l=0, v_h=1)(input_image)\n",
        "\n",
        "#Validation Generator\n",
        "val_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "#Train Generator with classical Augmentation techniques\n",
        "aug_train_data_gen = ImageDataGenerator(\n",
        "                                        height_shift_range=10,\n",
        "                                        width_shift_range=10,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=True, \n",
        "                                        fill_mode='nearest',\n",
        "                                        preprocessing_function = preprocess_input)\n",
        "\n",
        "#Train Generator with CutOut\n",
        "aug_train_data_gen_cut_out = ImageDataGenerator(\n",
        "                                        height_shift_range=10,\n",
        "                                        width_shift_range=10,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=True, \n",
        "                                        fill_mode='nearest',\n",
        "                                        preprocessing_function = custom_function) \n",
        "\n",
        "#Train Generator with MixUp\n",
        "train_gen_mixup = MixupImageDataGenerator(generator=aug_train_data_gen,\n",
        "                                    directory='train_data_final_80_20/train',\n",
        "                                    batch_size=8,\n",
        "                                    img_height=96,\n",
        "                                    img_width=96)                                  \n",
        "\n",
        "\n",
        "train_gen = aug_train_data_gen.flow_from_directory(directory='train_data_final_80_20/train',\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=labels, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=True) \n",
        "\n",
        "train_gen_cut_out = aug_train_data_gen_cut_out.flow_from_directory(directory='train_data_final_80_20/train',\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=labels, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=True)                                             \n",
        "\n",
        "val_gen = val_data_gen.flow_from_directory(directory='train_data_final_80_20/val',\n",
        "                                               target_size=(96,96),\n",
        "                                               color_mode='rgb',\n",
        "                                               classes=labels, # can be set to labels\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=False)"
      ],
      "metadata": {
        "id": "j2LwqoNiB0W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INITIALIZATION MODEL**"
      ],
      "metadata": {
        "id": "LAzGMub7DzF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Useful for implementation of Quasi-SVM\n",
        "from tensorflow.keras.layers.experimental import RandomFourierFeatures\n",
        "\n",
        "input_shape = (96, 96, 3)\n",
        "epochs = 200\n",
        "\n",
        "#Load ConvNextLarge Model from Keras\n",
        "supernet = tfk.applications.convnext.ConvNeXtLarge(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(96,96,3)\n",
        ")\n",
        "\n",
        "# Use the supernet as feature extractor\n",
        "supernet.trainable = False\n",
        "elastic_lambda = 1e-5"
      ],
      "metadata": {
        "id": "L2zzUUxeDqqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING TWO DIFFERENT MODELS**"
      ],
      "metadata": {
        "id": "qNbS_nKDEY7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *First Model: Implementation QUASI-SVM classier and training + Fine tuning with CutOut*"
      ],
      "metadata": {
        "id": "A_-8Jz7DEkKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tfk.Input(shape=(96,96,3))\n",
        "x = tfkl.Resizing(96, 96, interpolation=\"bicubic\")(inputs)\n",
        "x = supernet(x)\n",
        "x = tfkl.Flatten(name='Flattening')(x)\n",
        "x = tfkl.Dense(\n",
        "  512, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = tfkl.Dense(\n",
        "  256, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = tfkl.Dense(\n",
        "  256, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = tfkl.Dense(\n",
        "  256, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = tfkl.Dense(\n",
        "  128, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = RandomFourierFeatures(\n",
        "            output_dim=4096, scale=10.0, kernel_initializer=\"gaussian\"\n",
        "        )(x)\n",
        "outputs = tfkl.Dense(\n",
        "    units=8)(x)\n",
        "\n",
        "# Connect input and output through the Model class\n",
        "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile the model\n",
        "tl_model.compile(loss=tfk.losses.hinge, optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')\n",
        "tl_model.summary()"
      ],
      "metadata": {
        "id": "8T_2WEz0EXec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation of callbacks with EarlyStopping\n",
        "callbacks_a = [tfk.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=15, restore_best_weights=True)]\n",
        "rlr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
        "                                                        factor=0.1, \n",
        "                                                        patience=10, \n",
        "                                                        verbose=1, \n",
        "                                                        mode='auto', \n",
        "                                                        min_delta=0.000001)\n",
        "callbacks_a.append(rlr_callback)"
      ],
      "metadata": {
        "id": "msqwvCztFFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the weights to give more relevance to species less supported in the unbalanced dataset \n",
        "from collections import Counter\n",
        "counter = Counter(train_gen.classes)\n",
        "max_val = float(max(counter.values()))\n",
        "class_weights = {class_id : max_val/n_images for class_id, n_images in counter.items()}\n",
        "\n",
        "#Train the model with classical Augmentated train data\n",
        "t1_history = tl_model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = 200,\n",
        "    class_weight = class_weights,\n",
        "    validation_data = val_gen,\n",
        "    callbacks = callbacks_a\n",
        ").history"
      ],
      "metadata": {
        "id": "hSAQpGbbFRR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_model.save(\"convNextModel_first_model_tl\")"
      ],
      "metadata": {
        "id": "uf7eh6t4G2fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = tfk.models.load_model('convNextModel_first_model_tl')\n",
        "ft_model.summary()"
      ],
      "metadata": {
        "id": "BKx31N-UG9js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing only the first 250 layers so the others now are trainable \n",
        "ft_model.get_layer('convnext_large').trainable = True\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers[:250]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_model.summary()"
      ],
      "metadata": {
        "id": "30xoRc7UHCuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.compile(loss=tfk.losses.hinge, optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
        "\n",
        "#Fine tuning training with CutOut Augmentation\n",
        "t1_history = ft_model.fit(\n",
        "    x = train_gen_cut_out,\n",
        "    epochs = 200,\n",
        "    class_weight = class_weights,\n",
        "    validation_data = val_gen,\n",
        "    callbacks = callbacks_a\n",
        ").history"
      ],
      "metadata": {
        "id": "zMOIcYgcHLek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_model.save(\"convNextModel_first_model_cutout_ft\")\n",
        "#END FIRST MODEL"
      ],
      "metadata": {
        "id": "Vo4qa7OSHNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *Second Model: Implementation Dense Layers with SoftMax and training + Fine tuning with MixUp*"
      ],
      "metadata": {
        "id": "6s884l1rH_VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tfk.Input(shape=(96,96,3))\n",
        "x = tfkl.Resizing(96, 96, interpolation=\"bicubic\")(inputs)\n",
        "x = supernet(x)\n",
        "x = tfkl.Flatten(name='Flattening')(x)\n",
        "x = Dropout(0.2, seed=seed)(x)\n",
        "x = tfkl.Dense(\n",
        "  512, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = tfkl.Dense(\n",
        "  512, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "x = GaussianNoise(0.01)(x)\n",
        "x = tfkl.Dense(\n",
        "  512, \n",
        "  activation='relu',\n",
        "  kernel_initializer = tfk.initializers.HeUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "outputs = tfkl.Dense(\n",
        "  8, \n",
        "  activation='softmax',\n",
        "  kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "  kernel_regularizer=tf.keras.regularizers.L1(elastic_lambda))(x)\n",
        "\n",
        "# Connect input and output through the Model class\n",
        "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile the model\n",
        "tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')\n",
        "tl_model.summary()"
      ],
      "metadata": {
        "id": "PoI0y5MLH7dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_a = [tfk.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=15, restore_best_weights=True)]\n",
        "rlr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
        "                                                        factor=0.1, \n",
        "                                                        patience=10, \n",
        "                                                        verbose=1, \n",
        "                                                        mode='auto', \n",
        "                                                        min_delta=0.000001)\n",
        "callbacks_a.append(rlr_callback)"
      ],
      "metadata": {
        "id": "SQEdmuUWJA_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the weights to give more relevance to species less supported in the unbalanced dataset\n",
        "from collections import Counter\n",
        "counter = Counter(train_gen.classes)\n",
        "max_val = float(max(counter.values()))\n",
        "class_weights = {class_id : max_val/n_images for class_id, n_images in counter.items()}\n",
        "\n",
        "#Train the model with classical Augmentated train data\n",
        "t1_history = tl_model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = 200,\n",
        "    class_weight = class_weights,\n",
        "    validation_data = val_gen,\n",
        "    callbacks = callbacks_a)\n",
        ".history"
      ],
      "metadata": {
        "id": "cd9h0R1dJKAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_model.save(\"convNextModel_second_model_tl\")"
      ],
      "metadata": {
        "id": "7NxFVCtbJfKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = tfk.models.load_model('convNextModel_second_model_tl')\n",
        "ft_model.summary()"
      ],
      "metadata": {
        "id": "RxKOJT1UJo_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing only the first 240 layers so the others now are trainable \n",
        "ft_model.get_layer('convnext_large').trainable = True\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers[:240]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_model.summary()"
      ],
      "metadata": {
        "id": "AIdvyQKIJrkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
        "\n",
        "from collections import Counter\n",
        "counter = Counter(train_gen.classes)\n",
        "max_val = float(max(counter.values()))\n",
        "class_weights = {class_id : max_val/n_images for class_id, n_images in counter.items()}\n",
        "\n",
        "#Train the model with MixUp Augmentation\n",
        "ft_history = ft_model.fit(\n",
        "    x = train_gen_mixup,\n",
        "    epochs = 200,\n",
        "    steps_per_epoch = train_gen_mixup.get_steps_per_epoch(),\n",
        "    class_weight = class_weights,\n",
        "    validation_data = val_gen,\n",
        "    callbacks = callbacks_a\n",
        ").history"
      ],
      "metadata": {
        "id": "O1UhajeTJ1WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_model.save(\"convNextModel_second_model_mixup_ft\")\n",
        "#END SECOND MODEL"
      ],
      "metadata": {
        "id": "dnJCUEdjLhen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUILD A NEW MODEL WITH ENSEMBLE TECHNIQUES**"
      ],
      "metadata": {
        "id": "Pg2Y8cMULmqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load two models previously trained\n",
        "models=[]\n",
        "\n",
        "ft_model1 = tfk.models.load_model('convNextModel_first_model_cutout_ft')\n",
        "ft_model1._name=\"model_cutout_ft\"\n",
        "ft_model1.summary()\n",
        "models.append(ft_model1)\n",
        "\n",
        "ft_model2 = tfk.models.load_model('convNextModel_second_model_mixup_ft')\n",
        "ft_model2._name=\"model_mixup_ft\"\n",
        "ft_model2.summary()\n",
        "models.append(ft_model2)"
      ],
      "metadata": {
        "id": "C8Gev_QsLmFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tfk.Input(shape=(96,96,3))\n",
        "\n",
        "#Define the function for ensembling the models previously loaded\n",
        "def ensembleModels(models, model_input):\n",
        "    # collect outputs of models in a list\n",
        "    yModels=[model(model_input) for model in models] \n",
        "    # averaging outputs\n",
        "    yAvg=tfk.layers.average(yModels) \n",
        "    # build model from same input and avg output\n",
        "    modelEns = tfk.Model(inputs=model_input, outputs=yAvg, name='ensemble')  \n",
        "   \n",
        "    return modelEns\n",
        "\n",
        "modelEns = ensembleModels(models, inputs)\n",
        "\n",
        "#Evaluation of the new model in the validation set to check if it has better performance than the previous ones\n",
        "modelEns.compile(loss=tfk.losses.hinge, optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
        "modelEns.evaluate(val_gen, verbose=1)"
      ],
      "metadata": {
        "id": "B4U8tmWdL9QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save ensemble model\n",
        "modelEns.save(\"convNextModel_ensemble\")"
      ],
      "metadata": {
        "id": "b11VIeiqMM-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}